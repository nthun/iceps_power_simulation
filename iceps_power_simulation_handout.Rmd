---
title: "Using Monte Carlo simulation to estimate required sample size in R"
author: "Tamas Nagy"
date: "3/10/2020"
output: html_document
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE, message = FALSE, warning = FALSE}
# Install uninstalled packages
if(!require(tidyverse)) install.packages("tidyverse")
if(!require(lmerTest)) install.packages("lmerTest")
if(!require(broom.mixed)) install.packages("broom.mixed")
if(!require(devtools)) install.packages("devtools")
if(!require(faux)) devtools::install_github("debruine/faux")

# Load packages
library(tidyverse) # 
library(lmerTest)
library(broom)
library(faux)

knitr::opts_chunk$set(echo = TRUE)

theme_set(theme_light()) # Set plot theme
```

# 1. Create a prototype
## Define the hypothesis and make a prediction!

We hypothesize that the treatment will decrease the pain over time. Therefore we assume that at the baseline, we will have a similar value for pain, but for the post measurement, pain will be lower in the treatment group.

## The formula that will evaluate our hypothesis

Start with a simple study:
We have a treatment and control condition, and a 100 grade scale for pain as the outcome
We have a pre and a post measurement
The way we can write this formula down is:

`pain ~ group * time`

So now we know that we need: 

- An outcome, with 100 levels. Let's assume that this variable have a normal distribution.  
- Group variable with 2 levels: treatment and control.  
- Time variable with 2 levels: pre and post.

## Effect size

We need to figure out, how different will be the post measurement in the treatment group. 
For that, we need to come up with the Smallest Effect Size of Interest (SESOI). It is very easy, because we can define it on the original original scale (1-100), so we don't have to deal with effect sizes, etc. Let's say, that we assume that the SESOI as 5 units.
Let's generate the distribution of this variable!  

## Generate the outcome variable

We need to decide the mean and standard deviation of this variable.
Usually, we can find these values in journal articles, or make an educated guess.
Let's set the mean pain to 50, with a standard deviation of 10.
A great thing about this approach is that we can define any distribution, not just normal.

```{r proto outcome distribution}
pain_distribution <-    
  dnorm(x = 1:100, # Vecor of quantiles 1 to 100
        mean = 50, # Mean
        sd = 10) # SD 

# Let's visualize this distribution
# To do that, we need to put this into a data frame
tibble(x = 1:100, 
       y = pain_distribution) %>% 
  ggplot() +
  aes(x = x, y = y) +
  geom_line() +
  labs(title = "Theoretical distribution of the pain variable")
```

Now let's use this distribution to generate 1000 random data points!

```{r proto random variable}
pain_random <-
  sample(x = 1:100, # The possible values to choose from
       size = 1000, # How many values we want? 
       prob = pain_distribution, # The values will be normally distributed
       replace = TRUE) # Can we choose the same value more than one?

qplot(pain_random, bins = 30) +
  labs(title = "1000 generated random pain measurements")
```

According to the hypothesis, we should break down this 1000 values into 4 cells. Pre - control, post-control, pre-treatment, post-treatment. The post treatment needs to have a lower value by 5 units.
To do this, we will create a data frame:  

- we use the pain_random variable
- we create the groupings
- we subtract the SESOI (that we defined as 5 units) from the post-treatment condition.

```{r proto dataset}
# Define the groups
groups <- c("control_pre", "control_post", "treatment_pre", "treatment_post")

# Create a dataframe 
pain_df <-  
  tibble(id = gl(n = 500, k = 2), # Generate the id (everyone has 2 measurements)
         pain = pain_random, # Use the random pain variable that we generated
         group = gl(n = 4, k = 1, length = 1000, labels = groups) # Assign each case to one of the four groups
         ) %>% 
    # Subtract 5 from the pain values where the in the treatment_post group
    mutate(pain = if_else(condition = group == "treatment_post", 
                          true = pain - 5L, 
                          false = pain)) %>%
    # The group variable should be separated into group and time
    separate(col = group, 
             into = c("group", "time"), 
             sep = "_") %>%  
    # Let's set the group levels
    mutate(group = fct_relevel(group, "control"),
           time = fct_relevel(time, "pre")) 

# This is how our dataframe will look like
pain_df
```

```{r proto dataviz}

# We can also visualize the difference between the groups
pain_df %>% 
  group_by(group, time) %>% 
  summarise(avg_pain = mean(pain),
            se_pain = sd(pain)/sqrt(n())) %>% 
  ggplot() +
  aes(x = time, y = avg_pain, color = group, group = group,
      ymin = avg_pain - se_pain, ymax = avg_pain + se_pain) +
  geom_line(size = 1.2) +
  geom_linerange(size = 1.2, color = "black", alpha = .5) +
  geom_point(size = 5)

```


## See if there is a significant difference

We will use a mixed-effects model with random intercept, and particiupant id as the grouping variable.

```{r proto stats}

lmer(pain ~ group * time + (1|id), data = pain_df) %>% 
  summary()
```

As we can see, there is a significant interaction effect, and the difference is very close to the 5 units that we wanted. However, we had 500 participants, and we need to figure out if this effect is detectible with smaller effect sizes.
To do that, we need to break down this previous prototype into substitutible elements.

-----------------------------

It would be possible to run the previous the previous script several times, and see how the significance changes if we change the sample size or the standard deviation of the outcome measure. However, we could only say anything meaningful about each scenario, if we had several replications. Therefore, we should run the previous steps several times, and record the results. Sounds a tedious job! Fortunately, we can automate it!


# 2. Generalizing

In order to try out several different sample sizes, we need to create a function that generates the data with different parameters (such as the sample size), and evaluates if the result is significant or not. 

```{r}
# A function that generates a variable with random normal diu
# n: the number of values needed
# mean: theoretical mean
# sd: theoretical sd
generate_100 <- function(n, mean, sd){
  
  sample(x = 1:100, # The possible values to choose from
         size = n, # How many values we want? 
         prob = dnorm(x = 1:100, # Vecor of quantiles 1 to 100
                      mean = mean, 
                      sd = sd), # The values will be normally distributed
         replace = TRUE) # The same value can be chosen more than once
      
}

# Try out the function, and generate data that is centered at 30 and has an sd of 10
generate_100(10000, 30, 10) %>% 
  qplot(bins = 30) +
  coord_cartesian(xlim = c(0, 100))

```

Now, let's make a function that generates a whole data frame! This way, we can generate as many replications as we want.
To do this, we use the powerful feature of nested datasets. This means that each cell can hold a list element. For e.g. this way we can keep dataframes inside the cells of dataframes!


```{r}
# A function that generates a dataset based on theoretical parameters
# n: number of observations
# means: a vector of theoretical means for the groups
# sds: a vector of theoretical sds for the groups
# groups: a vecotor of group names
# times: the number of measurements for each group

generate_dataset <- function(n, means, sds, groups, times){
  
  # First we generate all possible combinations of groups and times. This will automate the variable name generation
crossing(group = groups, 
         time = 1:times) %>% 
  # Then we add the sample size and the theoretical parameters
  mutate(n = n, 
         t_mean = means, 
         t_sd = sds) %>% 
  # Then we generate data into the cells as nested list values
  mutate(value = pmap(list(n, t_mean, t_sd),
                     ~generate_100(..1, ..2, ..3)),
         # Generate ids for each data point. This will make it possible to connect data
         # ponits like they were coming from the same person
         id = map2(group, n, 
                   ~paste(.x, 1:.y, sep = "_"))) %>% 
  # Remove the theoretical parameters, but keep the sample size
  select(-t_mean, -t_sd) %>% 
  # Then unpack the data, that will be in long format
  unnest(c(value, id))
  
}

```

## Let's verify that the function  works as intended

- First we check if it can create a similar dataset than before
- Then we also check if it works with more than two groups and measurements


```{r}

trial_2x2 <-
  generate_dataset(n = 1000, 
                   means = c(50, 50, 50, 45), 
                   sds = 10,
                   groups = c("control", "treatment"),
                   times = 2)

trial_2x2 %>% 
  group_by(group, time) %>% 
  summarise(avg_pain = mean(value),
            sd_pain = sd(value),
            n = n())

# Works!

trial_2x3 <-
  generate_dataset(n = 1000, 
                   means = c(50, 50, 50, 50, 45, 40), 
                   sds = 10,
                   groups = c("control", "treatment"),
                   times = 3)

trial_2x3 %>% 
  group_by(group, time) %>% 
  summarise(avg_pain = mean(value),
            sd_pain = sd(value),
            n = n())

# Works!

trial_3x2 <-
  generate_dataset(n = 1000, 
                   means = c(50, 50, 50, 45, 50, 40), 
                   sds = c(10, 9, 9, 11, 8, 12),
                   groups = c("control", "treatment1", "treatment2"),
                   times = 2)

trial_3x2 %>% 
  group_by(group, time) %>% 
  summarise(avg_pain = mean(value),
            sd_pain = sd(value),
            n = n())

# Works!

```

It works pretty well in all circumstances! It is important to make it sure that the length of the factors is the same as grous x times, otherwise, R throws an error. 



## Creating the simulation matrix 

To be able to create replications for each scenario that we test, we need to define the sample sizes, and also the number of datasets for each sample size.
The more datasets we have for each sample size, the more reliable our estimation gets.
Each dataset should be numbered, just as each participant in the datasets. Again, we can use crossing to do this.

```{r}

crossing(group_size = seq(from = 30, to = 300, by = 30),
         replication = 1:50) %>% 
  mutate(dataset = map(group_size, 
                       ~generate_dataset(n = .x,
                                         means = c(50, 50, 50, 45), 
                                         sds = 10,
                                         groups = c("control", "treatment"),
                                         times = 2)))
```

## Embracing good (better) practices
It is not a good practice to hardcode the parameters into functions.
The good practice is to define the parameters in the beginning of the script, than we can feed the variables to the function. This way you only need to change your script at one place. Let's do that.
Also, please notice that the simulation now is starting to require more computational power. If you set a high number of replications, and wide range of sample sizes, it may get quite slow. For now, let's keep the number of replications low, so we don't need to wait for too long to run our code. We will have some tricks to speed up the code later!


```{r}
# Let's keep the parameters separate from the functions!

# These parameters define the simulation matrix
sample_increment = 30 # This defines the steps in the sample size 
min_sample = 30 # The minimum sample size
max_sample = 150 # The maximum sample size
replications = 50 # The number of replications for each scenario (sample size)

# These parameters define the datasets
means = c(50, 50, 50, 45) # The mean for the groups
sds = 10 # The sd for the measurements. Can be a vector too
groups = c("control", "treatment") # The name of the groups
times = 2 # The number of repeated measurements

# These parameters define the evaluation of the results
significance = .05 # The treshold for false positives (we will need this later)
critical_power = .80 # What is the minimal statistical power that we aim for

```

This is how we run the function without hard coded parameters

```{r }
sim_data <-
  crossing(group_size = seq(from = min_sample, 
                            to = max_sample, 
                            by = sample_increment),
           dataset = 1:replications) %>% 
  mutate(data = map(group_size, ~generate_dataset( n = .x,
                                                   means = means, 
                                                   sds = sds,
                                                   groups = groups,
                                                   times = times)))

```

Now, we need to test our hypothesis on each generated dataset. Again, we can use the nested structure, so we will store the model for each dataset in a variable of the dataframe.

```{r, warning=FALSE, message=FALSE}

sim_result <-
  sim_data %>% 
  mutate(model = map(data, 
                     # Run the formula to test the hypothesis
                     ~lmer(value ~ group * time + (1|id), 
                           data = .x) %>% 
                     # put the results into a tidy dataframe
                      broom.mixed::tidy()
                     ))

sim_result %>% 
    # Extract the p value of the interaction from the model
    mutate(p = map_dbl(model,
                       ~filter(.x, str_detect(term, "^group.*:time")) %>% 
                        pull(p.value)),
   # Generate a variable that evaluates if the significance is under the treshold
           sig = p <= .05) %>% 
  group_by(group_size) %>% 
  summarise(power = mean(sig))
  


  
```

# TODO: Replace own dataset function with sim_design() from faux?


```{r}
sim_data %>% 
  slice(50) %>% 
  unnest(data) %>% 
  lmer(value ~ group * time + (1|id), data = .) %>% 
  summary()

temp <- 
sim_data %>%
  slice(1) %>% 
  unnest(data) %>% 
  spread(time, value, sep = "_")
  
cor.test(x = temp$time_1, y = temp$time_2)

```



